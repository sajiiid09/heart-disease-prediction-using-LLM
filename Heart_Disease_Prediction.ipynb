{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de480b16",
      "metadata": {
        "id": "de480b16"
      },
      "source": [
        "\n",
        "### Heart Disease Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d73d78cc",
      "metadata": {
        "id": "d73d78cc"
      },
      "source": [
        "## 1. Introduction\n",
        "This project aims to predict whether a patient is likely to develop heart disease in the next 10 years based on health-related attributes. The motivation stems from the increasing prevalence of cardiovascular diseases and the need for early prediction systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501dde89",
      "metadata": {
        "id": "501dde89"
      },
      "source": [
        "## 2. Dataset Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29fc3d93",
      "metadata": {
        "id": "29fc3d93"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Heart Disease.csv\")\n",
        "df.info()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96892101",
      "metadata": {
        "id": "96892101"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.describe(include='all')\n",
        "\n",
        "# Correlation heatmap\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ceea83f",
      "metadata": {
        "id": "2ceea83f"
      },
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23921c24",
      "metadata": {
        "id": "23921c24"
      },
      "outputs": [],
      "source": [
        "\n",
        "output_col = 'Heart Disease (in next 10 years)'\n",
        "df[output_col].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Class Distribution in Output Feature')\n",
        "plt.xlabel('Heart Disease in 10 Years')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9109394c",
      "metadata": {
        "id": "9109394c"
      },
      "source": [
        "## 4. Dataset Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6ff158c",
      "metadata": {
        "id": "e6ff158c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Handle missing values\n",
        "df['education'].fillna(df['education'].mode()[0], inplace=True)\n",
        "df['cigsPerDay'].fillna(df['cigsPerDay'].median(), inplace=True)\n",
        "df['BPMeds'].fillna(0, inplace=True)\n",
        "df['totChol'].fillna(df['totChol'].mean(), inplace=True)\n",
        "df['BMI'].fillna(df['BMI'].mean(), inplace=True)\n",
        "df['glucose'].fillna(df['glucose'].mean(), inplace=True)\n",
        "\n",
        "# Encoding categorical\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "# Normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = df.drop(columns=['Heart Disease (in next 10 years)'])\n",
        "y = df['Heart Disease (in next 10 years)']\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ce8ab5",
      "metadata": {
        "id": "41ce8ab5"
      },
      "source": [
        "## 5. Dataset Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912bbae4",
      "metadata": {
        "id": "912bbae4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2dc1d42",
      "metadata": {
        "id": "a2dc1d42"
      },
      "source": [
        "## 6. Model Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e32195",
      "metadata": {
        "id": "75e32195"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy_score(y_test, preds),\n",
        "        'precision': precision_score(y_test, preds),\n",
        "        'recall': recall_score(y_test, preds),\n",
        "        'confusion_matrix': confusion_matrix(y_test, preds),\n",
        "        'roc_auc': roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
        "    }\n",
        "\n",
        "# Neural Network\n",
        "nn = Sequential()\n",
        "nn.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "nn.add(Dense(8, activation='relu'))\n",
        "nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "nn.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "nn_preds = (nn.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "results['Neural Network'] = {\n",
        "    'accuracy': accuracy_score(y_test, nn_preds),\n",
        "    'precision': precision_score(y_test, nn_preds),\n",
        "    'recall': recall_score(y_test, nn_preds),\n",
        "    'confusion_matrix': confusion_matrix(y_test, nn_preds),\n",
        "    'roc_auc': roc_auc_score(y_test, nn_preds)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a099b496",
      "metadata": {
        "id": "a099b496"
      },
      "source": [
        "## 7. Model Selection/Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e89b3d9",
      "metadata": {
        "id": "9e89b3d9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "names = list(results.keys())\n",
        "accuracies = [results[name]['accuracy'] for name in names]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.bar(names, accuracies, color='teal')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Comparison - Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Optional: ROC curves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c58149",
      "metadata": {
        "id": "21c58149"
      },
      "source": [
        "## 8. Conclusion\n",
        "From the model evaluation metrics, we observe that the Neural Network performs competitively with traditional models like Logistic Regression and KNN. Challenges included handling missing data and imbalanced class distributions. Further improvements can be made with more data or feature engineering."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}